{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "### Търсене и извличане на информация. Приложение на дълбоко машинно обучение\n",
    "### Стоян Михов\n",
    "### Зимен семестър 2020/2021\n",
    "#############################################################################\n",
    "###\n",
    "### Домашно задание 3\n",
    "###\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import generator\n",
    "import train\n",
    "import model\n",
    "import pickle\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parameters import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusFileName = 'corpusFunctions'\n",
    "modelFileName = 'modelLSTM'\n",
    "trainDataFileName = 'trainData'\n",
    "testDataFileName = 'testData'\n",
    "char2idFileName = 'char2id'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 32\n",
    "char_emb_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hid_size = 128\n",
    "lstm_layers = 2\n",
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaultTemperature = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateCode(model, char2id, startSentence, limit=1000, temperature=1.):\n",
    "    # model е инстанция на обучен LSTMLanguageModelPack обект\n",
    "    # char2id е речник за символите, връщащ съответните индекси\n",
    "    # startSentence е началния низ стартиращ със символа за начало '{'\n",
    "    # limit е горна граница за дължината на поемата\n",
    "    # temperature е температурата за промяна на разпределението за следващ символ\n",
    "    \n",
    "    result = startSentence[1:]\n",
    "    \n",
    "    id2char = dict(enumerate(char2id))\n",
    "\n",
    "    #Правим функция, която да предсказва всяка следваща буква\n",
    "    #по подобие на фиг. 1, следвайки фиг. 2 от заданието\n",
    "    def predict(model, source, h=None):\n",
    "        \n",
    "        X = model.preparePaddedBatch(source)\n",
    "        E = model.embed(X)\n",
    "        source_lengths = [len(s) for s in source]\n",
    "        if h != None:\n",
    "            outputPacked, h = model.lstm(torch.nn.utils.rnn.pack_padded_sequence(E, source_lengths, enforce_sorted = False), h)\n",
    "        else:\n",
    "            outputPacked, h = model.lstm(torch.nn.utils.rnn.pack_padded_sequence(E, source_lengths, enforce_sorted = False))\n",
    "        output,_ = torch.nn.utils.rnn.pad_packed_sequence(outputPacked)\n",
    "        Z = model.projection(model.dropout(output.flatten(0, 1)))\n",
    "        length = len(source) - 1\n",
    "        p = torch.nn.functional.softmax(torch.div(Z, temperature), dim = 1).data\n",
    "        p, topChar = p.topk(32)\n",
    "        topChar = topChar.numpy().squeeze()\n",
    "        p = p[length].numpy().squeeze()\n",
    "        if type(topChar[length]) is np.ndarray:\n",
    "            t = np.random.choice(topChar[length], p = p / np.sum(p))\n",
    "        else:\n",
    "            t = np.random.choice(topChar, p = p / np.sum(p))\n",
    "        return id2char[t], h \n",
    "\n",
    "    #Проверяваме дали е въведена начална дума\n",
    "    #Ако е въведена - добавяме отстояние след нея\n",
    "    #Иначе генерираме случайна главна буква, с която да започнем\n",
    "    if(len(startSentence) == 1):\n",
    "        chars = list(char2id.keys())\n",
    "        letters = chars[ord('a'):ord('z')] # ord() cast char to int\n",
    "        startSentence += np.random.choice(letters)\n",
    "    else:\n",
    "        startSentence += \" \"\n",
    "    initWordSize = len(result)\n",
    "    \n",
    "    python_function = [x for x in result] # текущото състояние на функцията\n",
    "    output, h = predict(model, python_function)\n",
    "    python_function.append(output)\n",
    "    model.eval()\n",
    "    \n",
    "    size = initWordSize\n",
    "    while not output == '}' and size <= limit :\n",
    "        output, h = predict(model, python_function[size], h)\n",
    "        python_function.append(output)\n",
    "        size = size + 1\n",
    "    result = \"\"\n",
    "    for ch in python_function:\n",
    "        result += ch\n",
    "\n",
    "    #### Край на Вашия код\n",
    "    #############################################################################\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "### Търсене и извличане на информация. Приложение на дълбоко машинно обучение\n",
    "### Стоян Михов\n",
    "### Зимен семестър 2020/2021\n",
    "#############################################################################\n",
    "###\n",
    "### Домашно задание 3\n",
    "###\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "####  LSTM с пакетиране на партида\n",
    "#################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMLanguageModelPack(torch.nn.Module):\n",
    "    def preparePaddedBatch(self, source):\n",
    "        device = next(self.parameters()).device\n",
    "        m = max(len(s) for s in source)\n",
    "        sents = [[self.word2ind.get(w, self.unkTokenIdx)\n",
    "                  for w in s] for s in source]\n",
    "        sents_padded = [s+(m-len(s))*[self.padTokenIdx] for s in sents]\n",
    "        return torch.t(torch.tensor(sents_padded, dtype=torch.long, device=device))\n",
    "    def save(self, fileName):\n",
    "        torch.save(self.state_dict(), fileName)\n",
    "    def load(self, fileName):\n",
    "        self.load_state_dict(torch.load(fileName))\n",
    "    def __init__(self, embed_size, hidden_size, word2ind, unkToken, padToken, endToken, lstm_layers, dropout):\n",
    "        super(LSTMLanguageModelPack, self).__init__()\n",
    "        #############################################################################\n",
    "        ###  Тук следва да се имплементира инициализацията на обекта\n",
    "        ###  За целта може да копирате съответния метод от програмата за упр. 13\n",
    "        ###  като направите добавки за повече слоеве на РНН и dropout\n",
    "        #############################################################################\n",
    "        #### Начало на Вашия код.\n",
    "        self.word2ind = word2ind\n",
    "        self.unkTokenIdx = word2ind[unkToken]\n",
    "        self.padTokenIdx = word2ind[padToken]\n",
    "        self.endTokenIdx = word2ind[endToken]\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = torch.nn.LSTM(\n",
    "            embed_size, hidden_size, lstm_layers, dropout=dropout)\n",
    "        self.embed = torch.nn.Embedding(len(word2ind), embed_size)\n",
    "        self.projection = torch.nn.Linear(hidden_size, len(word2ind))\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "        #### Край на Вашия код\n",
    "        #############################################################################\n",
    "    def forward(self, source):\n",
    "        #############################################################################\n",
    "        ###  Тук следва да се имплементира forward метода на обекта\n",
    "        ###  За целта може да копирате съответния метод от програмата за упр. 13\n",
    "        ###  като направите добавка за dropout\n",
    "        #############################################################################\n",
    "        #### Начало на Вашия код.\n",
    "        X = self.preparePaddedBatch(source)\n",
    "        E = self.embed(X[:-1])\n",
    "        source_lengths = [len(s)-1 for s in source]\n",
    "        outputPacked, _ = self.lstm(torch.nn.utils.rnn.pack_padded_sequence(\n",
    "            E, source_lengths, enforce_sorted=False))\n",
    "        output, _ = torch.nn.utils.rnn.pad_packed_sequence(outputPacked)\n",
    "        Z = self.projection(self.dropout(output.flatten(0, 1)))\n",
    "        Y_bar = X[1:].flatten(0, 1)\n",
    "        Y_bar[Y_bar == self.endTokenIdx] = self.padTokenIdx\n",
    "        H = torch.nn.functional.cross_entropy(\n",
    "            Z, Y_bar, ignore_index=self.padTokenIdx)\n",
    "        return H\n",
    "\n",
    "        #### Край на Вашия код\n",
    "        #############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startChar = 'ш'\n",
    "endChar = 'щ'\n",
    "unkChar = 'ь'\n",
    "padChar = 'ъ'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testCorpus, trainCorpus, char2id = utils.prepareData(\n",
    "    corpusFileName, startChar, endChar, unkChar, padChar)\n",
    "pickle.dump(testCorpus, open(testDataFileName, 'wb'))\n",
    "pickle.dump(trainCorpus, open(trainDataFileName, 'wb'))\n",
    "pickle.dump(char2id, open(char2idFileName, 'wb'))\n",
    "print('Data prepared.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testCorpus = pickle.load(open(testDataFileName, 'rb'))\n",
    "trainCorpus = pickle.load(open(trainDataFileName, 'rb'))\n",
    "char2id = pickle.load(open(char2idFileName, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = model.LSTMLanguageModelPack(char_emb_size, hid_size, char2id, unkChar,\n",
    "                                    padChar, endChar, lstm_layers=lstm_layers, dropout=dropout).to(device)\n",
    "if len(sys.argv) > 2:\n",
    "    lm.load(sys.argv[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(lm.parameters(), lr=learning_rate)\n",
    "train.trainModel(trainCorpus, lm, optimizer, epochs, batchSize)\n",
    "lm.save(modelFileName)\n",
    "print('Model perplexity: ', train.perplexity(lm, testCorpus, batchSize))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testCorpus = pickle.load(open(testDataFileName, 'rb'))\n",
    "char2id = pickle.load(open(char2idFileName, 'rb'))\n",
    "lm = model.LSTMLanguageModelPack(char_emb_size, hid_size, char2id,\n",
    "                                    unkChar, padChar, endChar, lstm_layers=lstm_layers, dropout=dropout)\n",
    "lm.load(modelFileName)\n",
    "print('Model perplexity: ', train.perplexity(lm, testCorpus, batchSize))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sys.argv) > 2:\n",
    "    seed = sys.argv[2]\n",
    "else:\n",
    "    seed = startChar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert seed[0] == startChar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sys.argv) > 3:\n",
    "    temperature = float(sys.argv[3])\n",
    "else:\n",
    "    temperature = defaultTemperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2id = pickle.load(open(char2idFileName, 'rb'))\n",
    "lm = model.LSTMLanguageModelPack(char_emb_size, hid_size, char2id,\n",
    "                                    unkChar, padChar, endChar, lstm_layers=lstm_layers, dropout=dropout)\n",
    "lm.load(modelFileName)\n",
    "print(generator.generateCode(lm, char2id, seed, temperature=temperature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(trainCorpus, lm, optimizer, epochs, batchSize):\n",
    "    idx = np.arange(len(trainCorpus), dtype='int32')\n",
    "    lm.train()\n",
    "    for epoch in range(epochs):\n",
    "        np.random.shuffle(idx)\n",
    "        for b in range(0, len(idx), batchSize):\n",
    "            batch = [trainCorpus[i] for i in idx[b:min(b+batchSize, len(idx))]]\n",
    "            H = lm(batch)\n",
    "            optimizer.zero_grad()\n",
    "            H.backward()\n",
    "            optimizer.step()\n",
    "            print(\"Epoch:\", epoch, '/', epochs, \", Batch:\", b //\n",
    "                  batchSize, '/', len(idx) // batchSize, \", loss: \", H.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(lm, testCorpus, batchSize):\n",
    "    lm.eval()\n",
    "    H = 0.\n",
    "    c = 0\n",
    "    for b in range(0, len(testCorpus), batchSize):\n",
    "        batch = testCorpus[b:min(b+batchSize, len(testCorpus))]\n",
    "        l = sum(len(s)-1 for s in batch)\n",
    "        c += l\n",
    "        with torch.no_grad():\n",
    "            H += l * lm(batch)\n",
    "    return math.exp(H/c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "### Търсене и извличане на информация. Приложение на дълбоко машинно обучение\n",
    "### Стоян Михов\n",
    "### Зимен семестър 2020/2021\n",
    "#############################################################################\n",
    "###\n",
    "### Упражнение 13\n",
    "###\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import nltk\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "###  Визуализация на прогреса\n",
    "#############################################################\n",
    "class progressBar:\n",
    "    def __init__(self ,barWidth = 50):\n",
    "        self.barWidth = barWidth\n",
    "        self.period = None\n",
    "    def start(self, count):\n",
    "        self.item=0\n",
    "        self.period = int(count / self.barWidth)\n",
    "        sys.stdout.write(\"[\"+(\" \" * self.barWidth)+\"]\")\n",
    "        sys.stdout.flush()\n",
    "        sys.stdout.write(\"\\b\" * (self.barWidth+1))\n",
    "    def tick(self):\n",
    "        if self.item>0 and self.item % self.period == 0:\n",
    "            sys.stdout.write(\"-\")\n",
    "            sys.stdout.flush()\n",
    "        self.item += 1\n",
    "    def stop(self):\n",
    "        sys.stdout.write(\"]\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractDictionary(corpus, limit=20000):\n",
    "    pb = progressBar()\n",
    "    pb.start(len(corpus))\n",
    "    dictionary = {}\n",
    "    for doc in corpus:\n",
    "        pb.tick()\n",
    "        for w in doc:\n",
    "            if w not in dictionary: dictionary[w] = 0\n",
    "        dictionary[w] += 1\n",
    "    L = sorted([(w,dictionary[w]) for w in dictionary], key = lambda x: x[1] , reverse=True)\n",
    "    if limit > len(L): limit = len(L)\n",
    "    words = [ w for w,_ in L[:limit] ] + [unkToken] + [padToken]\n",
    "    word2ind = { w:i for i,w in enumerate(words)}\n",
    "    pb.stop()\n",
    "    return words, word2ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitSentCorpus(fullSentCorpus, testFraction = 0.1):\n",
    "    random.seed(42)\n",
    "    random.shuffle(fullSentCorpus)\n",
    "    testCount = int(len(fullSentCorpus) * testFraction)\n",
    "    testSentCorpus = fullSentCorpus[:testCount]\n",
    "    trainSentCorpus = fullSentCorpus[testCount:]\n",
    "    return testSentCorpus, trainSentCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "#######   Зареждане на корпуса\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_root = 'JOURNALISM.BG/C-MassMedia'\n",
    "myCorpus = PlaintextCorpusReader(corpus_root, '.*\\.txt')\n",
    "startToken = '<s>'\n",
    "endToken = '</s>'\n",
    "unkToken = '<unk>'\n",
    "padToken = '<pad>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [ [startToken] + [w.lower() for w in sent] + [endToken] for sent in myCorpus.sents()]\n",
    "words, word2ind = extractDictionary(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testCorpus, trainCorpus  = splitSentCorpus(corpus, testFraction = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 32\n",
    "emb_size = 50\n",
    "hid_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "device = torch.device(\"cpu\")<br>\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "#### LSTM с пакетиране на партида\n",
    "#################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMLanguageModelPack(torch.nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, word2ind, unkToken, padToken):\n",
    "        super(LSTMLanguageModelPack, self).__init__()\n",
    "        self.word2ind = word2ind\n",
    "        self.unkTokenIdx = word2ind[unkToken]\n",
    "        self.padTokenIdx = word2ind[padToken]\n",
    "        self.lstm = torch.nn.LSTM(embed_size, hidden_size)\n",
    "        self.embed = torch.nn.Embedding(len(word2ind), embed_size)\n",
    "        self.projection = torch.nn.Linear(hidden_size,len(word2ind))\n",
    "    \n",
    "    def preparePaddedBatch(self, source):\n",
    "        device = next(self.parameters()).device\n",
    "        m = max(len(s) for s in source)\n",
    "        sents = [[self.word2ind.get(w,self.unkTokenIdx) for w in s] for s in source]\n",
    "        sents_padded = [ s+(m-len(s))*[self.padTokenIdx] for s in sents]\n",
    "        return torch.t(torch.tensor(sents_padded, dtype=torch.long, device=device))\n",
    "    def forward(self, source):\n",
    "        X = self.preparePaddedBatch(source)\n",
    "        E = self.embed(X[:-1])\n",
    "        source_lengths = [len(s)-1 for s in source]\n",
    "        outputPacked, _ = self.lstm(torch.nn.utils.rnn.pack_padded_sequence(E, source_lengths,enforce_sorted=False))\n",
    "        output,_ = torch.nn.utils.rnn.pad_packed_sequence(outputPacked)\n",
    "        Z = self.projection(output.flatten(0,1))\n",
    "        Y_bar = X[1:].flatten(0,1)\n",
    "        H = torch.nn.functional.cross_entropy(Z,Y_bar,ignore_index=self.padTokenIdx)\n",
    "        return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LSTMLanguageModelPack(emb_size, hid_size, word2ind, unkToken, padToken).to(device)\n",
    "optimizer = torch.optim.Adam(lm.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.arange(len(trainCorpus), dtype='int32')\n",
    "np.random.shuffle(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in range(0, len(idx), batchSize):\n",
    "    batch = [ trainCorpus[i] for i in idx[b:min(b+batchSize, len(idx))] ]\n",
    "    H = lm(batch)\n",
    "    optimizer.zero_grad()\n",
    "    H.backward()\n",
    "    optimizer.step()\n",
    "    if b % 10 == 0:\n",
    "        print(b, '/', len(idx), H.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(lm, testCorpus, batchSize):\n",
    "    H = 0.\n",
    "    c = 0\n",
    "    for b in range(0,len(testCorpus),batchSize):\n",
    "        batch = testCorpus[b:min(b+batchSize, len(testCorpus))]\n",
    "        l = sum(len(s)-1 for s in batch)\n",
    "        c += l\n",
    "        with torch.no_grad():\n",
    "            H += l * lm(batch)\n",
    "    return math.exp(H/c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "####  Двупосочен LSTM с пакетиране на партида\n",
    "#################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMLanguageModelPack(torch.nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, word2ind, unkToken, padToken, endToken):\n",
    "        super(BiLSTMLanguageModelPack, self).__init__()\n",
    "        self.word2ind = word2ind\n",
    "        self.unkTokenIdx = word2ind[unkToken]\n",
    "        self.padTokenIdx = word2ind[padToken]\n",
    "        self.endTokenIdx = word2ind[endToken]\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = torch.nn.LSTM(embed_size, hidden_size, bidirectional=True)\n",
    "        self.embed = torch.nn.Embedding(len(word2ind), embed_size)\n",
    "        self.projection = torch.nn.Linear(2*hidden_size,len(word2ind))\n",
    "    def preparePaddedBatch(self, source):\n",
    "        device = next(self.parameters()).device\n",
    "        m = max(len(s) for s in source)\n",
    "        sents = [[self.word2ind.get(w,self.unkTokenIdx) for w in s] for s in source]\n",
    "        sents_padded = [ s+(m-len(s))*[self.padTokenIdx] for s in sents]\n",
    "        return torch.t(torch.tensor(sents_padded, dtype=torch.long, device=device))\n",
    "    def forward(self, source):\n",
    "        batch_size = len(source)\n",
    "        X = self.preparePaddedBatch(source)\n",
    "        E = self.embed(X)\n",
    "        \n",
    "        source_lengths = [len(s) for s in source]\n",
    "        m = X.shape[0]\n",
    "        outputPacked, _ = self.lstm(torch.nn.utils.rnn.pack_padded_sequence(E, source_lengths,enforce_sorted=False))\n",
    "        \n",
    "        output,_ = torch.nn.utils.rnn.pad_packed_sequence(outputPacked)\n",
    "        output = output.view(m, batch_size, 2, self.hidden_size)\n",
    "        t = torch.cat((output[:-2,:,0,:], output[2:,:,1,:]),2)\n",
    "        Z = self.projection(t.flatten(0,1))\n",
    "        Y_bar = X[1:-1].flatten(0,1)\n",
    "        Y_bar[Y_bar==self.endTokenIdx] = self.padTokenIdx\n",
    "        H = torch.nn.functional.cross_entropy(Z,Y_bar,ignore_index=self.padTokenIdx)\n",
    "        return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blm = BiLSTMLanguageModelPack(emb_size, hid_size, word2ind, unkToken, padToken, endToken).to(device)\n",
    "optimizer = torch.optim.Adam(blm.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.arange(len(trainCorpus), dtype='int32')\n",
    "np.random.shuffle(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in range(0, len(idx), batchSize):\n",
    "    batch = [ trainCorpus[i] for i in idx[b:min(b+batchSize, len(idx))] ]\n",
    "    H = blm(batch)\n",
    "    optimizer.zero_grad()\n",
    "    H.backward()\n",
    "    optimizer.step()\n",
    "    if b % 10 == 0:\n",
    "        print(b, '/', len(idx), H.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(blm, testCorpus, batchSize):\n",
    "    H = 0.\n",
    "    c = 0\n",
    "    for b in range(0,len(testCorpus),batchSize):\n",
    "        batch = testCorpus[b:min(b+batchSize, len(testCorpus))]\n",
    "        l = sum(len(s)-2 for s in batch)\n",
    "        c += l\n",
    "        with torch.no_grad():\n",
    "            H += l * blm(batch)\n",
    "    return math.exp(H/c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "#### LSTM класификатор на документи\n",
    "#################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(torch.nn.Module):\n",
    "    def __init__(self, langModel, classesCount):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.langModel = langModel\n",
    "        self.classProjection = torch.nn.Linear(langModel.lstm.hidden_size,classesCount)\n",
    "    \n",
    "    def forward(self, source):\n",
    "        X = self.langModel.preparePaddedBatch(source)\n",
    "        E = self.langModel.embed(X[:-1])\n",
    "        source_lengths = [len(s)-1 for s in source]\n",
    "        _, (h,_) = self.langModel.lstm(torch.nn.utils.rnn.pack_padded_sequence(E, source_lengths,enforce_sorted=False))\n",
    "        \n",
    "        Z = self.classProjection(torch.squeeze(h,dim=0))\n",
    "        return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileNames = myCorpus.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecoCorpus = [ [startToken] + [w.lower() for w in myCorpus.words(f)] + [endToken] for f in fileNames if f.find('E-Economy'+'/')==0 ]\n",
    "milCorpus = [ [startToken] + [w.lower() for w in myCorpus.words(f)] + [endToken] for f in fileNames if f.find('S-Military'+'/')==0 ]\n",
    "polCorpus = [ [startToken] + [w.lower() for w in myCorpus.words(f)] + [endToken] for f in fileNames if f.find('J-Politics'+'/')==0 ]\n",
    "culCorpus = [ [startToken] + [w.lower() for w in myCorpus.words(f)] + [endToken] for f in fileNames if f.find('C-Culture'+'/')==0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testEcoCorpus, trainEcoCorpus = splitSentCorpus(ecoCorpus)\n",
    "testMilCorpus, trainMilCorpus = splitSentCorpus(milCorpus)\n",
    "testPolCorpus, trainPolCorpus = splitSentCorpus(polCorpus)\n",
    "testCulCorpus, trainCulCorpus = splitSentCorpus(culCorpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainClassCorpus = trainEcoCorpus + trainMilCorpus + trainPolCorpus + trainCulCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = np.concatenate((\n",
    "                         np.ones(len(trainEcoCorpus),dtype='int32')*0,\n",
    "                         np.ones(len(trainMilCorpus),dtype='int32')*1,\n",
    "                         np.ones(len(trainPolCorpus),dtype='int32')*2,\n",
    "                         np.ones(len(trainCulCorpus),dtype='int32')*3\n",
    "                         ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testY = np.concatenate((\n",
    "                        np.ones(len(testEcoCorpus),dtype='int32')*0,\n",
    "                        np.ones(len(testMilCorpus),dtype='int32')*1,\n",
    "                        np.ones(len(testPolCorpus),dtype='int32')*2,\n",
    "                        np.ones(len(testCulCorpus),dtype='int32')*3\n",
    "                        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.arange(len(trainClassCorpus), dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classModel = LSTMClassifier(lm,4).to(device)\n",
    "optimizer = torch.optim.Adam(classModel.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(idx)\n",
    "for b in range(0, len(idx), batchSize):\n",
    "    batch = [ trainClassCorpus[i] for i in idx[b:min(b+batchSize, len(idx))] ]\n",
    "    target = torch.tensor(trainY[idx[b:min(b+batchSize, len(idx))]], dtype = torch.long, device = device)\n",
    "    Z = classModel(batch)\n",
    "    H = torch.nn.functional.cross_entropy(Z,target)\n",
    "    optimizer.zero_grad()\n",
    "    H.backward()\n",
    "    optimizer.step()\n",
    "    if b % 10 == 0:\n",
    "        print(b, '/', len(idx), H.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testClassCorpus = [ testEcoCorpus, testMilCorpus, testPolCorpus, testCulCorpus ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma(s):\n",
    "    with torch.no_grad():\n",
    "        Z = classModel([s])\n",
    "        return torch.argmax(Z[0]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testClassifier(testClassCorpus, gamma):\n",
    "    L = [ len(c) for c in testClassCorpus ]\n",
    "    pb = progressBar(50)\n",
    "    pb.start(sum(L))\n",
    "    classesCount = len(testClassCorpus)\n",
    "    confusionMatrix = [ [0] * classesCount for _ in range(classesCount) ]\n",
    "    for c in range(classesCount):\n",
    "        for text in testClassCorpus[c]:\n",
    "            pb.tick()\n",
    "            c_MAP = gamma(text)\n",
    "            confusionMatrix[c][c_MAP] += 1\n",
    "    pb.stop()\n",
    "    precision = []\n",
    "    recall = []\n",
    "    Fscore = []\n",
    "    for c in range(classesCount):\n",
    "        extracted = sum(confusionMatrix[x][c] for x in range(classesCount))\n",
    "        if confusionMatrix[c][c] == 0:\n",
    "            precision.append(0.0)\n",
    "            recall.append(0.0)\n",
    "            Fscore.append(0.0)\n",
    "        else:\n",
    "            precision.append( confusionMatrix[c][c] / extracted )\n",
    "            recall.append( confusionMatrix[c][c] / L[c] )\n",
    "            Fscore.append((2.0 * precision[c] * recall[c]) / (precision[c] + recall[c]))\n",
    "    P = sum( L[c] * precision[c] / sum(L) for c in range(classesCount) )\n",
    "    R = sum( L[c] * recall[c] / sum(L) for c in range(classesCount) )\n",
    "    F1 = (2*P*R) / (P + R)\n",
    "    print('=================================================================')\n",
    "    print('Матрица на обърквания: ')\n",
    "    for row in confusionMatrix:\n",
    "        for val in row:\n",
    "            print('{:4}'.format(val), end = '')\n",
    "        print()\n",
    "    print('Прецизност: '+str(precision))\n",
    "    print('Обхват: '+str(recall))\n",
    "    print('F-оценка: '+str(Fscore))\n",
    "    print('Обща презизност: '+str(P))\n",
    "    print('Общ обхват: '+str(R))\n",
    "    print('Обща F-оценка: '+str(F1))\n",
    "    print('=================================================================')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "#### Двупосочен LSTM класификатор на документи\n",
    "#################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMClassifier(torch.nn.Module):\n",
    "    def __init__(self, langModel, classesCount):\n",
    "        super(BiLSTMClassifier, self).__init__()\n",
    "        self.langModel = langModel\n",
    "        self.classProjection = torch.nn.Linear(2*langModel.hidden_size,classesCount)\n",
    "    \n",
    "    def forward(self, source):\n",
    "        batch_size = len(source)\n",
    "        X = self.langModel.preparePaddedBatch(source)\n",
    "        E = self.langModel.embed(X)\n",
    "        source_lengths = [len(s) for s in source]\n",
    "        _, (h,c) = self.langModel.lstm(torch.nn.utils.rnn.pack_padded_sequence(E, source_lengths,enforce_sorted=False))\n",
    "        h = h.view(2,batch_size,self.langModel.hidden_size)\n",
    "        \n",
    "        Z = self.classProjection(torch.cat([h[0],h[1]],1))\n",
    "        return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classModel = BiLSTMClassifier(blm,4).to(device)\n",
    "optimizer = torch.optim.Adam(classModel.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.arange(len(trainClassCorpus), dtype='int32')\n",
    "np.random.shuffle(idx)\n",
    "for b in range(0, len(idx), batchSize):\n",
    "    batch = [ trainClassCorpus[i] for i in idx[b:min(b+batchSize, len(idx))] ]\n",
    "    target = torch.tensor(trainY[idx[b:min(b+batchSize, len(idx))]], dtype = torch.long, device = device)\n",
    "    \n",
    "    Z = classModel(batch)\n",
    "    H = torch.nn.functional.cross_entropy(Z,target)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    H.backward()\n",
    "    optimizer.step()\n",
    "    if b % 10 == 0:\n",
    "        print(b, '/', len(idx), H.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "#### Конволюционен класификатор на документи\n",
    "#################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionClassifier(torch.nn.Module):\n",
    "    def __init__(self, embed, filterSize, filterCount, classesCount, word2ind, unkToken, padToken):\n",
    "        super(ConvolutionClassifier, self).__init__()\n",
    "        self.embed = embed\n",
    "        self.word2ind = word2ind\n",
    "        self.unkTokenIdx = word2ind[unkToken]\n",
    "        self.padTokenIdx = word2ind[padToken]\n",
    "        self.convolution = torch.nn.Conv1d(in_channels=embed.embedding_dim, out_channels=filterCount, kernel_size=filterSize)\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "        self.classProjection = torch.nn.Linear(filterCount,classesCount)\n",
    "    \n",
    "    def preparePaddedBatch(self, source):\n",
    "        device = next(self.parameters()).device\n",
    "        m = max(len(s) for s in source)\n",
    "        sents = [[self.word2ind.get(w,self.unkTokenIdx) for w in s] for s in source]\n",
    "        sents_padded = [ s+(m-len(s))*[self.padTokenIdx] for s in sents]\n",
    "        return torch.tensor(sents_padded, dtype=torch.long, device=device)\n",
    "    \n",
    "    def forward(self, source):\n",
    "        X = self.preparePaddedBatch(source)\n",
    "        \n",
    "        E = torch.transpose(self.embed(X),1,2)\n",
    "        ### Очаква се Е да е тензор с размер (batch_size, embed_size, max_sent_len)\n",
    "        U,_ = torch.max(torch.relu(self.convolution(E)), dim=2)\n",
    "        Z = self.classProjection(self.dropout(U))\n",
    "        return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB = lm.embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classModel = ConvolutionClassifier(EMB, 7, 400, 4, word2ind, unkToken, padToken).to(device)\n",
    "optimizer = torch.optim.Adam(classModel.parameters(), lr=0.01, weight_decay=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.arange(len(trainClassCorpus), dtype='int32')\n",
    "classModel.train()\n",
    "for epoch in range(10):\n",
    "    np.random.shuffle(idx)\n",
    "    for b in range(0, len(idx), batchSize):\n",
    "        batch = [ trainClassCorpus[i] for i in idx[b:min(b+batchSize, len(idx))] ]\n",
    "        target = torch.tensor(trainY[idx[b:min(b+batchSize, len(idx))]], dtype = torch.long, device = device)\n",
    "    \n",
    "        Z = classModel(batch)\n",
    "        H = torch.nn.functional.cross_entropy(Z,target)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        H.backward()\n",
    "        optimizer.step()\n",
    "        if b % 10 == 0:\n",
    "            print(b, '/', len(idx), H.item())\n",
    "classModel.eval()\n",
    "testClassifier(testClassCorpus, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "#### LSTM с посимволово влагане с КНН и пакетиране на партида\n",
    "#################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharEmbedding(torch.nn.Module):\n",
    "    def __init__(self, word2ind, char_embed_size, word_embed_size, filter_size=5, dropoutrate=0.3, padding=1):\n",
    "        super(CharEmbedding, self).__init__()\n",
    "        self.word2ind = word2ind\n",
    "        self.char_embed_size = char_embed_size\n",
    "        self.word_embed_size = word_embed_size\n",
    "        self.filter_size = filter_size\n",
    "        self.dropoutrate = dropoutrate\n",
    "        self.padding = padding\n",
    "        alphabetSet = {c for w in word2ind for c in w}\n",
    "        alphabet = ['§','`','~','№']+list(alphabetSet)\n",
    "        self.char2id = {c:i for i, c in enumerate(alphabet) }\n",
    "        self.char_pad = self.char2id['§']\n",
    "        self.start_of_word = self.char2id['`']\n",
    "        self.end_of_word = self.char2id['~']\n",
    "        self.char_unk = self.char2id['№']\n",
    "        self.CharEmbedding = torch.nn.Embedding(len(self.char2id),self.char_embed_size, padding_idx = self.char_pad)\n",
    "        self.conv = torch.nn.Conv1d(char_embed_size, word_embed_size, filter_size, padding=padding)\n",
    "        self.highway_proj = torch.nn.Linear(word_embed_size,word_embed_size)\n",
    "        self.highway_gate = torch.nn.Linear(word_embed_size,word_embed_size)\n",
    "        self.Dropout = torch.nn.Dropout(dropoutrate)\n",
    "    def preparePaddedBatch(self, source):\n",
    "        device = next(self.parameters()).device\n",
    "        source_ids = [[ [self.start_of_word] + [self.char2id.get(c, self.char_unk) for c in w ] + [self.end_of_word] for w in s] for s in source]\n",
    "        max_word_length = max(len(w) for s in source_ids for w in s )\n",
    "        max_sent_len = max(len(s) for s in source_ids)\n",
    "    \n",
    "        sents_padded = []\n",
    "        for sentence in source_ids:\n",
    "            sent_padded = [ w + [self.char_pad]*(max_word_length-len(w)) for w in sentence ] + [[self.char_pad]*max_word_length] * (max_sent_len - len(sentence))\n",
    "            sents_padded.append(sent_padded)\n",
    "        return torch.transpose(torch.tensor(sents_padded, dtype=torch.long, device=device),0,1).contiguous()\n",
    "    def forward(self, source):\n",
    "        batch_size = len(source)\n",
    "        X = self.preparePaddedBatch(source)\n",
    "        X_emb = self.CharEmbedding(X).transpose(2,3)\n",
    "        x_conv = self.conv(X_emb.flatten(0,1))\n",
    "        x_conv_out0,_ = torch.max(torch.nn.functional.relu(x_conv),dim=2)\n",
    "        x_conv_out = x_conv_out0.view((-1,batch_size,self.word_embed_size))\n",
    "        x_proj = torch.nn.functional.relu(self.highway_proj(x_conv_out))\n",
    "        x_gate = torch.sigmoid(self.highway_gate(x_conv_out))\n",
    "        x_highway = x_gate * x_proj + (1 - x_gate) * x_conv_out\n",
    "        output = self.Dropout(x_highway)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharCNNLSTMLanguageModelPack(torch.nn.Module):\n",
    "    def __init__(self, word_embed_size, hidden_size, word2ind, unkToken, padToken, char_embed_size, filter_size=5, dropoutrate=0.3, padding=1):\n",
    "        super(CharCNNLSTMLanguageModelPack, self).__init__()\n",
    "        self.word2ind = word2ind\n",
    "        self.unkTokenIdx = word2ind[unkToken]\n",
    "        self.padTokenIdx = word2ind[padToken]\n",
    "        self.charEmbedding = CharEmbedding(word2ind, char_embed_size, word_embed_size, filter_size, dropoutrate, padding)\n",
    "        self.lstm = torch.nn.LSTM(word_embed_size, hidden_size)\n",
    "        self.projection = torch.nn.Linear(hidden_size,len(word2ind))\n",
    "    \n",
    "    def preparePaddedBatch(self, source):\n",
    "        device = next(self.parameters()).device\n",
    "        m = max(len(s) for s in source)\n",
    "        sents = [[self.word2ind.get(w,self.unkTokenIdx) for w in s] for s in source]\n",
    "        sents_padded = [ s+(m-len(s))*[self.padTokenIdx] for s in sents]\n",
    "        return torch.t(torch.tensor(sents_padded, dtype=torch.long, device=device))\n",
    "    \n",
    "    def forward(self, source):\n",
    "        X = self.preparePaddedBatch(source)\n",
    "        E = self.charEmbedding(source)\n",
    "        source_lengths = [len(s)-1 for s in source]\n",
    "        outputPacked, _ = self.lstm(torch.nn.utils.rnn.pack_padded_sequence(E, source_lengths,enforce_sorted=False))\n",
    "        output,_ = torch.nn.utils.rnn.pad_packed_sequence(outputPacked)\n",
    "        \n",
    "        Z = self.projection(output.flatten(0,1))\n",
    "        Y_bar = X[1:].flatten(0,1)\n",
    "        H = torch.nn.functional.cross_entropy(Z,Y_bar,ignore_index=self.padTokenIdx)\n",
    "        return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = CharCNNLSTMLanguageModelPack(256, 256, word2ind, unkToken, padToken, 32).to(device)\n",
    "optimizer = torch.optim.Adam(lm.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.arange(len(trainCorpus), dtype='int32')\n",
    "np.random.shuffle(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.train()\n",
    "for b in range(0, len(idx), batchSize):\n",
    "    batch = [ trainCorpus[i] for i in idx[b:min(b+batchSize, len(idx))] ]\n",
    "    H = lm(batch)\n",
    "    optimizer.zero_grad()\n",
    "    H.backward()\n",
    "    optimizer.step()\n",
    "    if b % 10 == 0:\n",
    "        print(b, '/', len(idx), H.item())\n",
    "lm.eval()\n",
    "perplexity(lm, testCorpus, batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "####  Двупосочен LSTM с пакетиране на партида\n",
    "#################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharCNNBiLSTMLanguageModelPack(torch.nn.Module):\n",
    "    def __init__(self, word_embed_size, hidden_size, word2ind, unkToken, padToken, endToken, char_embed_size, filter_size=5, dropoutrate=0.3, padding=1):\n",
    "        super(CharCNNBiLSTMLanguageModelPack, self).__init__()\n",
    "        self.word2ind = word2ind\n",
    "        self.unkTokenIdx = word2ind[unkToken]\n",
    "        self.padTokenIdx = word2ind[padToken]\n",
    "        self.endTokenIdx = word2ind[endToken]\n",
    "        self.hidden_size = hidden_size\n",
    "        self.charEmbedding = CharEmbedding(word2ind, char_embed_size, word_embed_size, filter_size, dropoutrate, padding)\n",
    "        self.lstm = torch.nn.LSTM(word_embed_size, hidden_size, bidirectional=True)\n",
    "        self.projection = torch.nn.Linear(2*hidden_size,len(word2ind))\n",
    "    \n",
    "    def preparePaddedBatch(self, source):\n",
    "        device = next(self.parameters()).device\n",
    "        m = max(len(s) for s in source)\n",
    "        sents = [[self.word2ind.get(w,self.unkTokenIdx) for w in s] for s in source]\n",
    "        sents_padded = [ s+(m-len(s))*[self.padTokenIdx] for s in sents]\n",
    "        return torch.t(torch.tensor(sents_padded, dtype=torch.long, device=device))\n",
    "    \n",
    "    def forward(self, source):\n",
    "        batch_size = len(source)\n",
    "        X = self.preparePaddedBatch(source)\n",
    "        E = self.charEmbedding(source)\n",
    "        source_lengths = [len(s) for s in source]\n",
    "        m = X.shape[0]\n",
    "        outputPacked, _ = self.lstm(torch.nn.utils.rnn.pack_padded_sequence(E, source_lengths,enforce_sorted=False))\n",
    "        \n",
    "        output,_ = torch.nn.utils.rnn.pad_packed_sequence(outputPacked)\n",
    "        output = output.view(m, batch_size, 2, self.hidden_size)\n",
    "        t = torch.cat((output[:-2,:,0,:], output[2:,:,1,:]),2)\n",
    "        Z = self.projection(t.flatten(0,1))\n",
    "        \n",
    "        Y_bar = X[1:-1].flatten(0,1)\n",
    "        Y_bar[Y_bar==self.endTokenIdx] = self.padTokenIdx\n",
    "        H = torch.nn.functional.cross_entropy(Z,Y_bar,ignore_index=self.padTokenIdx)\n",
    "        return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blm = CharCNNBiLSTMLanguageModelPack(256, 256, word2ind, unkToken, padToken, endToken, 32).to(device)\n",
    "optimizer = torch.optim.Adam(blm.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.arange(len(trainCorpus), dtype='int32')\n",
    "np.random.shuffle(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blm.train()\n",
    "for b in range(0, len(idx), batchSize):\n",
    "    batch = [ trainCorpus[i] for i in idx[b:min(b+batchSize, len(idx))] ]\n",
    "    H = blm(batch)\n",
    "    optimizer.zero_grad()\n",
    "    H.backward()\n",
    "    optimizer.step()\n",
    "    if b % 10 == 0:\n",
    "        print(b, '/', len(idx), H.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "### Търсене и извличане на информация. Приложение на дълбоко машинно обучение\n",
    "### Стоян Михов\n",
    "### Зимен семестър 2020/2021\n",
    "##########################################################################\n",
    "###\n",
    "### Домашно задание 3\n",
    "###\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusSplitString = ';)\\n'\n",
    "maxProgramLength = 10000\n",
    "symbolCountThreshold = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitSentCorpus(fullSentCorpus, testFraction=0.1):\n",
    "    random.seed(42)\n",
    "    random.shuffle(fullSentCorpus)\n",
    "    testCount = int(len(fullSentCorpus) * testFraction)\n",
    "    testSentCorpus = fullSentCorpus[:testCount]\n",
    "    trainSentCorpus = fullSentCorpus[testCount:]\n",
    "    return testSentCorpus, trainSentCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAlphabet(corpus):\n",
    "    symbols = {}\n",
    "    for s in corpus:\n",
    "        for c in s:\n",
    "            if c in symbols:\n",
    "                symbols[c] += 1\n",
    "            else:\n",
    "                symbols[c] = 1\n",
    "    return symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(corpusFileName, startChar, endChar, unkChar, padChar):\n",
    "    file = open(corpusFileName, 'r')\n",
    "    poems = file.read().split(corpusSplitString)\n",
    "    symbols = getAlphabet(poems)\n",
    "    assert startChar not in symbols and endChar not in symbols and unkChar not in symbols and padChar not in symbols\n",
    "    charset = [startChar, endChar, unkChar, padChar] + \\\n",
    "        [c for c in sorted(symbols) if symbols[c] > symbolCountThreshold]\n",
    "    char2id = {c: i for i, c in enumerate(charset)}\n",
    "    corpus = []\n",
    "    for i, s in enumerate(poems):\n",
    "        if len(s) > 0:\n",
    "            corpus.append([startChar] + [s[i]\n",
    "                          for i in range(min(len(s), maxProgramLength))] + [endChar])\n",
    "    testCorpus, trainCorpus = splitSentCorpus(corpus, testFraction=0.01)\n",
    "    print('Corpus loading completed.')\n",
    "    return testCorpus, trainCorpus, char2id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
